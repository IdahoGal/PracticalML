fitMod1 <- rpart(classe ~., data=Training, method="class")
?rpart
library(knitr)
library(caret)
library(ggplot2)
library(randomForest)
library(rpart)
library(rpart.plot)
?rpart
train <- read.csv("training.csv", na.strings=c("", "NA", "#DIV/0!", "<NA>"))
test <- read.csv("test.csv", na.strings=c("", "NA", "#DIV/0!", "<NA>"))
count.Cols <- dim(train)[2]
train <- train[,colSums(is.na(train)) == 0]
test <- test[,colSums(is.na(test)) == 0]
nzindex <- nearZeroVar(train)
# Remove columns belonging to nzindex
train <- train[,-nzindex]
# Remove columns not useful for prediction: x, user_name, and date related columns
train <- train[, -c(1:7)]
adData <- data.frame(train)
trainIndex = createDataPartition(y=train$classe, p = 0.80, list=FALSE)
Training = adData[trainIndex,]
Testing = adData[-trainIndex,]
fitMod1 <- rpart(classe ~., data=Training, method="class")
Testing$classe = factor(Testing$classe)
fitMod1 <- rpart(classe ~., data=Training, method="class")
res <- errorest(classe~., data=Testing, model=rpart, predict=fitMod1 = )
res <- errorest(classe~., data=Testing, model=rpart, predict=fitMod1)
fitMod1 <- rpart(classe ~., data=Training, method="class")
predMod1 <- predict(fitMod1, Testing, type = "class")
fitMod1
predMod1
cm1 <- confusionMatrix(predMod1, Testing$classe)
cm1
?randomForest
fitMod2 <- randomForest(classe ~., data=Training, method="class")
predMod2 <- predict(fitMod2, Testing, type = "class")
predMod2
cm2 <- confusionMatrix(predMod2, Testing$classe)
cm2$table
cm2
predMod1 <- rpart.plot(fitMod1, main="Classification Tree", extra=102, under=TRUE, faclen=0)
fitMod1 <- rpart(classe ~., data=Training, method="class")
predMod1 <- predict(fitMod1, Testing, type = "class")
cm1 <- confusionMatrix(predMod1, Testing$classe)
cm1$table
cm1
printcp(fitMod1)
vi = varImp(predMod2)
library(AppliedPredictiveModeling)
vi = varImp(predMod2)
vi = varImp(predMod2)
fitMod2 <- randomForest(classe ~., data=Training, method="class")
vi = varImp(fitMod2)
varImp(fitMod2)
vi$var <- rownames(vi)
vi = as.data.frame(vi[with(vi,order[vi$Overall, decreasing=TRUE)),])
rownames(vi) <- NULL
print (vi)
rownames(vi)
print (vi)
predMod2 <- predict(fitMod2, Testing, type = "class")
predMod2
fitMod2$finalModel
predMod2 <- predict(fitMod2, Testing, type = "class")
predMod2
predMod2$testcases <- 1:nrow(predMod2)
nrow(predMod2)
predprob <- predict(fitMod2, test, type = "prob")
predprob$testcase <- 1:nrow(predprob)
predprob <- gather( predprob, "class", "prob", 1:5)
?gather
??gather
fitMod3 <- train(classe ~., data=Training, method = "rf",
trControl=trainControl(method="cv", number = 3),
prox=TRUE, allowParallel=TRUE)
rf <- randomForest( classe ~., data=Training)
rf <- randomForest( classe ~., data=Training)
rf
adData <- data.frame(train)
trainIndex = createDataPartition(y=train$classe, p = 0.60, list=FALSE)
Training = adData[trainIndex,]
Testing = adData[-trainIndex,]
dim(Training)
ggplot(data = Training, aes(x=classe), fill = factor(classe)) +
geom_histogram(binwidth=.5, colour="black", fill="pink") +
xlab("Classe") + ylab("Count") + labs(title="Classe vs. Count")
fitMod1 <- rpart(classe ~., data=Training, method="class")
# Prediction:
predMod1 <- predict(fitMod1, Testing, type = "class")
rpart.plot(fitMod1, main="Classification Tree", extra=102, under=TRUE, faclen=0)
cm1 <- confusionMatrix(predMod1, Testing$classe)
cm1$table
printcp(fitMod1)
fitMod2 <- randomForest(classe ~., data=Training, method="class")
# Prediction:
predMod2 <- predict(fitMod2, Testing, type = "class")
cm2 <- confusionMatrix(predMod2, Testing$classe)
cm2$table
accuracyMod1 <-  postResample(predMod1, Testing$classe)
accuracyMod2 <-  postResample(predMod2, Testing$classe)
OutOfSampleErr1 <- 1 - accuracyMod1
OutOfSampleErr2 <- 1 - accuracyMod2
accuracyMod2
fitMod3 <- train(classe ~., data=Training, method = "rf",
trControl=trainControl(method="cv", number = 3),
prox=TRUE, allowParallel=TRUE)
fitMod3
?randomForest
fitMod3$finalModel
